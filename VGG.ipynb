{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMy1aiZf+d00hnjpXpyKitH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xjtulyc/lyc_code/blob/master/VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckg2O0ZRidzj"
      },
      "source": [
        "# VGG16 Tensorflow实现\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho7fB5H4iolF"
      },
      "source": [
        "## VGG16 神经网络\n",
        "VGG，又叫VGG-16，顾名思义就是有16层，包括13个卷积层和3个全连接层，是由Visual Geometry Group组的Simonyan和Zisserman在文献《Very Deep Convolutional Networks for Large Scale Image Recognition》中提出卷积神经网络模型，该模型主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。其年参加了ImageNet图像分类与定位挑战赛，取得了在分类任务上排名第二，在定位任务上排名第一的优异成绩。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkYyjS4IjVUL"
      },
      "source": [
        "## 结构\n",
        "根据卷积核大小与卷积层数目不同，VGG可以分为6种子模型，分别是A、A-LRN、B、C、D、E，我们常看到的基本是D、E这两种模型，让我们看下面官方给出的6种结构图：\n",
        "\n",
        "\n",
        "<img src='https://img-blog.csdnimg.cn/20210310095311914.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1OTk4MDQx,size_16,color_FFFFFF,t_70#pic_center'>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EyssKD6kmZQ"
      },
      "source": [
        "以配置D为例，在卷积层1（conv3-64）,卷积层2（conv3-128）,卷积层3（conv3-256）,卷积层4（conv3-512）分别有64个，128个，256个，512个3X3卷积核，在每两层之间有池化层为移动步长为2的2X2池化矩阵（maxpool）。在卷积层5（conv3-512）后有全连接层，再之后是soft-max预测层。\n",
        "\n",
        "\n",
        "这张图可能会更好地理解\n",
        "\n",
        "\n",
        "<img src='https://img-blog.csdnimg.cn/20210310115556457.png#pic_center'>\n",
        "\n",
        "\n",
        "图像张量尺寸变化：224->112->56->28->14->7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMmMSHEyk8Hq"
      },
      "source": [
        "## 数据与训练\n",
        "\n",
        "1. 输入处理\n",
        "\n",
        "如果要使用224x224的图作为训练的输入，用S表示图片最小边的值，当S=224时这个图就直接使用，直接将多余的部分减掉；对于S远大于224的，模型将对图像进行单尺度和多尺度的剪裁，通过剪切这个图片中包含object的子图作为训练数据。\n",
        "\n",
        "2. 训练方式\n",
        "\n",
        "采用带动量的小批量梯度下降法，来优化目标函数，并且当学习效果较为满意时，最初加入的学习率权重衰减系数会起作用，会减小学习率，缓慢达到最优解。\n",
        "\n",
        "3. 初始化\n",
        "\n",
        "若为浅层，则先随机初始化后训练，深层采用浅层训练后的数据作为初始化数据，中间层则随机初始化。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl1-jvCclT3Z"
      },
      "source": [
        "## 特色\n",
        "\n",
        "1. 卷积层均采用相同的卷积核参数，这样就能够使得每一个卷积层（张量）与前一层（张量）保持相同的宽和高；\n",
        "\n",
        "2. 池化层均采用相同的池化核参数，池化层采用尺寸为2X2，stride=2，max的池化方式，使得池化后的层尺寸长宽为未池化前的1/2；\n",
        "\n",
        "3. 利用小尺寸卷积核等效大尺寸卷积核，2个3X3卷积核的感受野与1个5X5卷积核相当，3个3X3卷积核与1个7X7卷积核相当，故在特征提取效果相当时，多个小卷核与大卷积核相比，学习参数更少，计算量较小，训练更加快速，还能增加网络的深度，提升模型性能。\n",
        "\n",
        "下面用计算说明为什么2个3X3卷积核能代替1个5X5卷积核：\n",
        "\n",
        "<img src='https://img-blog.csdnimg.cn/20210310111310615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1OTk4MDQx,size_16,color_FFFFFF,t_70#pic_center'>\n",
        "\n",
        "假设feature map是28×28的，假设卷记的步长step=1，padding=0：\n",
        "\n",
        "使用一层5X5卷积核\n",
        "\n",
        "由(28−5)/1+1=24可得，输出的feature map为24X24\n",
        "使用两层3X3卷积核\n",
        "\n",
        "第一层，由(28−3)/1+1=26可得，输出的feature map为26X26\n",
        "\n",
        "第二层，由(26−3)/1+1=24可得，输出的feature map为24X24\n",
        "\n",
        "故最终尺寸结果相等，用3X3卷积核代替7X7卷积核同理。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai0ISFPHlpgs"
      },
      "source": [
        "## 实验结果\n",
        "\n",
        "### 单尺度评估\n",
        "<img src=''>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt5Kur-8cV7q"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDxNPRx0cscH",
        "outputId": "d0897d6c-d444-40cc-e389-518ad71deb5a"
      },
      "source": [
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "dataset = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = dataset.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfVEvn0of_9c",
        "outputId": "f46690c7-3295-4b97-b711-7fa76861886f"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Um6SZyghuR"
      },
      "source": [
        "class VGG16(Model):\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.c1 = Conv2D(filters=64, kernel_size=(3, 3), padding='same')  # 卷积层1\n",
        "        self.b1 = BatchNormalization()  # BN层1\n",
        "        self.a1 = Activation('relu')  # 激活层1\n",
        "        self.c2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', )\n",
        "        self.b2 = BatchNormalization()  # BN层1\n",
        "        self.a2 = Activation('relu')  # 激活层1\n",
        "        self.p1 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d1 = Dropout(0.2)  # dropout层\n",
        "\n",
        "        self.c3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')\n",
        "        self.b3 = BatchNormalization()  # BN层1\n",
        "        self.a3 = Activation('relu')  # 激活层1\n",
        "        self.c4 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')\n",
        "        self.b4 = BatchNormalization()  # BN层1\n",
        "        self.a4 = Activation('relu')  # 激活层1\n",
        "        self.p2 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d2 = Dropout(0.2)  # dropout层\n",
        "\n",
        "        self.c5 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')\n",
        "        self.b5 = BatchNormalization()  # BN层1\n",
        "        self.a5 = Activation('relu')  # 激活层1\n",
        "        self.c6 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')\n",
        "        self.b6 = BatchNormalization()  # BN层1\n",
        "        self.a6 = Activation('relu')  # 激活层1\n",
        "        self.c7 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')\n",
        "        self.b7 = BatchNormalization()\n",
        "        self.a7 = Activation('relu')\n",
        "        self.p3 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d3 = Dropout(0.2)\n",
        "\n",
        "        self.c8 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b8 = BatchNormalization()  # BN层1\n",
        "        self.a8 = Activation('relu')  # 激活层1\n",
        "        self.c9 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b9 = BatchNormalization()  # BN层1\n",
        "        self.a9 = Activation('relu')  # 激活层1\n",
        "        self.c10 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b10 = BatchNormalization()\n",
        "        self.a10 = Activation('relu')\n",
        "        self.p4 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d4 = Dropout(0.2)\n",
        "\n",
        "        self.c11 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b11 = BatchNormalization()  # BN层1\n",
        "        self.a11 = Activation('relu')  # 激活层1\n",
        "        self.c12 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b12 = BatchNormalization()  # BN层1\n",
        "        self.a12 = Activation('relu')  # 激活层1\n",
        "        self.c13 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b13 = BatchNormalization()\n",
        "        self.a13 = Activation('relu')\n",
        "        self.p5 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d5 = Dropout(0.2)\n",
        "\n",
        "        self.flatten = Flatten()\n",
        "        self.f1 = Dense(512, activation='relu')\n",
        "        self.d6 = Dropout(0.2)\n",
        "        self.f2 = Dense(512, activation='relu')\n",
        "        self.d7 = Dropout(0.2)\n",
        "        self.f3 = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.c1(x)\n",
        "        x = self.b1(x)\n",
        "        x = self.a1(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.a2(x)\n",
        "        x = self.p1(x)\n",
        "        x = self.d1(x)\n",
        "\n",
        "        x = self.c3(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.a3(x)\n",
        "        x = self.c4(x)\n",
        "        x = self.b4(x)\n",
        "        x = self.a4(x)\n",
        "        x = self.p2(x)\n",
        "        x = self.d2(x)\n",
        "\n",
        "        x = self.c5(x)\n",
        "        x = self.b5(x)\n",
        "        x = self.a5(x)\n",
        "        x = self.c6(x)\n",
        "        x = self.b6(x)\n",
        "        x = self.a6(x)\n",
        "        x = self.c7(x)\n",
        "        x = self.b7(x)\n",
        "        x = self.a7(x)\n",
        "        x = self.p3(x)\n",
        "        x = self.d3(x)\n",
        "\n",
        "        x = self.c8(x)\n",
        "        x = self.b8(x)\n",
        "        x = self.a8(x)\n",
        "        x = self.c9(x)\n",
        "        x = self.b9(x)\n",
        "        x = self.a9(x)\n",
        "        x = self.c10(x)\n",
        "        x = self.b10(x)\n",
        "        x = self.a10(x)\n",
        "        x = self.p4(x)\n",
        "        x = self.d4(x)\n",
        "\n",
        "        x = self.c11(x)\n",
        "        x = self.b11(x)\n",
        "        x = self.a11(x)\n",
        "        x = self.c12(x)\n",
        "        x = self.b12(x)\n",
        "        x = self.a12(x)\n",
        "        x = self.c13(x)\n",
        "        x = self.b13(x)\n",
        "        x = self.a13(x)\n",
        "        x = self.p5(x)\n",
        "        x = self.d5(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.f1(x)\n",
        "        x = self.d6(x)\n",
        "        x = self.f2(x)\n",
        "        x = self.d7(x)\n",
        "        y = self.f3(x)\n",
        "        return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "LuaLCG1Dg3u9",
        "outputId": "cb81f53b-bc10-44e0-801c-3fa57ea758fa"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model = VGG16()\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "  checkpoint_save_path = \"./checkpoint/VGG16.ckpt\"\n",
        "  if os.path.exists(checkpoint_save_path + '.index'):\n",
        "      print('-------------load the model-----------------')\n",
        "      model.load_weights(checkpoint_save_path)\n",
        "\n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
        "                                                  save_weights_only=True,\n",
        "                                                  save_best_only=True)\n",
        "\n",
        "  history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1,\n",
        "                      callbacks=[cp_callback])\n",
        "  model.summary()\n",
        "\n",
        "  # print(model.trainable_variables)\n",
        "  file = open('./weights.txt', 'w')\n",
        "  for v in model.trainable_variables:\n",
        "      file.write(str(v.name) + '\\n')\n",
        "      file.write(str(v.shape) + '\\n')\n",
        "      file.write(str(v.numpy()) + '\\n')\n",
        "  file.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-12c8c86493c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1,\n\u001b[0;32m---> 18\u001b[0;31m                       callbacks=[cp_callback])\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"vgg16\" (type VGG16).\n    \n    in user code:\n    \n        File \"<ipython-input-4-6b4182335752>\", line 66, in call  *\n            x = self.c1(x)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 227, in assert_input_compatibility\n            raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n    \n        ValueError: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 28, 28)\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(32, 28, 28), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywSOZ8Nxg68-"
      },
      "source": [
        "###############################################    show   ###############################################\n",
        "\n",
        "# 显示训练集和验证集的acc和loss曲线\n",
        "acc = history.history['sparse_categorical_accuracy']\n",
        "val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}